---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import numpy as np
```

```{python}
def reiterate(how_many_times=100):
    def decorator(func):
        results = []
        
        def wrapper(*args, **kwargs):
            for i in range(how_many_times):
                results.append(func(*args, **kwargs))
            return results
        return wrapper
    return decorator
```

```{python}
#Parameters
N = 500 #Number of neurons
L = 100  #Number of memories (e.g. length of a list of words)

f = .3  #Sparseness of memory representation
```

```{python}
#Build encodings for memories as random sparse binary vectors (rows in a matrix L x N)
mtx = np.zeros((L, N)) 
mask = np.random.uniform(size = (L, N)) < f #Each entry in an encoding is 1 with probability f (and 0 with probability 1-f)
mtx[mask] = 1.

#Compute scalar products between all pairs of encodings
sim = mtx @ mtx.T
np.fill_diagonal(sim, 0) #Remove diagonal entries

step_0 = np.arange(L)
step_1 = np.argmax(sim, axis=1) #Transition to the argmax of each row
step_2 = step_1[step_1] #Equivalent to: np.argmax(sim[first_transition], axis=1)

two_loops_fraction = np.mean(step_0 == step_2)

print(two_loops_fraction)
```

```{python}
500 * 100
```

```{python}
from uncertainties import ufloat

def continuum_two_hops_fraction(L : int = 100):
    """
    Construct an L x L symmetric random matrix from i.i.d. random values chosen from a uniform distribution between (0, 10).
    In this approximation, entries are not likely to be repeated more than 2 times (one in the upper part, and one in the lower one),
    which holds true in the discrete case for N >> L >> 1.
    Starting from an element i, a transition occurs to the element j = argmax of i-th row. This function simulates two such steps,
    and counts the fraction of two-hop-paths that return to the starting element (i.e. they are two-hop loops). 
    This is found to be approximately equal to .5.
    """
    
    mtx = np.random.uniform(0, 10, size=(L, L))
    sim = np.tril(mtx) + np.tril(mtx, -1).T #Symmetrize
    np.fill_diagonal(sim, 0) #Remove diagonal entries

    step_0 = np.arange(L)
    step_1 = np.argmax(sim, axis=1)
    step_2 = step_1[step_1]

    two_loops_fraction = np.mean(step_0 == step_2)
    
    return two_loops_fraction


stats = reiterate(1000)(continuum_two_hops_fraction)(L=500) #Collect statistics

fraction = ufloat(np.mean(stats), np.std(stats))

print(f"Two-hop loops probability: {fraction:.2u}")
```

```{python}
plt.hist(np.max(sim, axis=1))
```

```{python}
sim
```

```{python}
import matplotlib.pyplot as plt
```

```{python}
plt.hist(np.max(sim, axis=1), bins=20)
```

```{python}
def similarities(N : int = 100,
                 L : int = 50, 
                 f : float = .3):
    
    #Build encodings for memories as random sparse binary vectors (rows in a matrix L x N)
    mtx = np.zeros((L, N)) 
    mask = np.random.uniform(size = (L, N)) < f #Each entry in an encoding is 1 with probability f (and 0 with probability 1-f)
    mtx[mask] = 1.

    #Compute scalar products between all pairs of encodings
    sim = mtx @ mtx.T
    np.fill_diagonal(sim, 0) #Remove diagonal entries

    #Simulate two steps
    step_0 = np.arange(L)
    step_1 = np.argmax(sim, axis=1) #Transition to the argmax of each row
    step_2 = step_1[step_1] #Equivalent to: np.argmax(sim[first_transition], axis=1)

    two_loops_fraction = np.mean(step_0 == step_2) #Fraction of paths that return to the starting point in two hops (A -> B -> A)
    
    return two_loops_fraction
#    print(f"Two-loops percentage (S_kn is max in row k AND row n): {two_loops_fraction * 100}%")
```

```{python}

```

```{python}
all_results = reiterate(10)(similarities)(100, 100, .3)
print(np.mean(all_results))
```

```{python}

```
