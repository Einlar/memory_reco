---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import numpy as np
import matplotlib.pyplot as plt

from numba import njit, prange #Accelerator

from p_tqdm import p_umap #Parallel processing

from functools import partial

from tqdm.notebook import tqdm

from mpl2latex import mpl2latex, latex_figsize
import pandas as pd
```

```{python}
@njit
def simulate_sparse_dynamics(index, L = 100, N = 1000, f = 0.01):
    
    #Compute similarity matrix
    mtx = np.zeros((L, N))
    mask = np.random.uniform(0., 1., size=(L, N)) < f
    
    for row_idx in range(mtx.shape[0]): #fill ones
        mtx[row_idx][mask[row_idx]] = 1

#     for row in range(L):
#         n_entries = np.random.binomial(N, f)
#         indices = np.random.choice(np.arange(N), size=n_entries, replace=False)
#         for idx in indices:
#             mtx[row][idx] = 1

    sim = mtx @ mtx.T
    np.fill_diagonal(sim, 0)

    #assert np.all(np.any(sim[0].reshape(-1,1) == sim, axis=1)), "A row must not be filled with all equal values"
    #There should be at least two different values in each row, or else the algorithm fails
    
    next_index = np.zeros(L, dtype=np.uint64)
    second_next_index = np.zeros(L, dtype=np.uint64)
    
    for row_idx in range(mtx.shape[0]): #Extract highest and second highest index from each row
        max_val = np.max(sim[row_idx])
        max_idx = np.flatnonzero(sim[row_idx] == max_val) 
        
        next_index[row_idx] = np.random.choice(max_idx)
        
        sim[row_idx][max_idx] = -1 #Remove max value. The new maximum is now the second highest value
        max_val = np.max(sim[row_idx])
        max_idx = np.flatnonzero(sim[row_idx] == max_val)
        
        second_next_index[row_idx] = np.random.choice(max_idx)
        
    #---Simulate dynamics---#
    prec_state = np.zeros(L, dtype=np.uint64) #Initialize
    curr_state = np.arange(L, dtype=np.uint64)

    visited = np.eye(L, dtype=np.uint64) #Each row is a binary vector storing the visited elements of each trial

    prec_tot_visited = 0 
    curr_tot_visited = L #Total number of visited elements (sum over all trials) 
    
    max_patience = 10 #If no new element is visited in any trial for this many iterations, then exit the loop and declare convergence
    curr_patience = max_patience #Counter that decreases whenever no trial visits a new item during a whole iteration. If it reaches 0, the loop is terminated.
    
    n_iter = 0 #Counter for iterations

    while True:
        n_iter += 1

        #Update
        next_state = next_index[curr_state] 
        mask = (next_state == prec_state) #If a direct backward step has happened
        next_state[mask] = second_next_index[curr_state][mask] #Correct it

        prec_state, curr_state = curr_state, next_state #Advance
        
        for i in range(L):
            visited[i][curr_state[i]] = 1
        
        curr_tot_visited = visited.sum()
        
        if curr_tot_visited > prec_tot_visited: #If some trial has visited a new element
            curr_patience    = max_patience
            prec_tot_visited = curr_tot_visited
        else:
            curr_patience -= 1

        if curr_patience <= 0: #Exit condition
            break

    lengths = np.sum(visited, axis=1) 

    return np.mean(lengths)
```

```{python}
@njit
def simulate_sparse_dynamics_symm(L = 100):
    
    #Compute similarity matrix
    mtx = np.random.uniform(0, 10, size=(L, L))
    sim = np.tril(mtx) + np.tril(mtx, -1).T #Symmetrize
    np.fill_diagonal(sim, 0) #Remove diagonal entries

    next_index = np.zeros(L, dtype=np.uint64)
    second_next_index = np.zeros(L, dtype=np.uint64)
    
    for row_idx in range(mtx.shape[0]): #Extract highest and second highest index from each row
        max_val = np.max(sim[row_idx])
        max_idx = np.flatnonzero(sim[row_idx] == max_val) 
        
        next_index[row_idx] = np.random.choice(max_idx)
        
        sim[row_idx][max_idx] = -1 #Remove max value. The new maximum is now the second highest value
        max_val = np.max(sim[row_idx])
        max_idx = np.flatnonzero(sim[row_idx] == max_val)
        
        second_next_index[row_idx] = np.random.choice(max_idx)
        
    #---Simulate dynamics---#
    prec_state = np.zeros(L, dtype=np.uint64) #Initialize
    curr_state = np.arange(L, dtype=np.uint64)

    visited = np.eye(L, dtype=np.uint64) #Each row is a binary vector storing the visited elements of each trial

    prec_tot_visited = 0 
    curr_tot_visited = L #Total number of visited elements (sum over all trials) 
    
    max_patience = 10 #If no new element is visited in any trial for this many iterations, then exit the loop and declare convergence
    curr_patience = max_patience #Counter that decreases whenever no trial visits a new item during a whole iteration. If it reaches 0, the loop is terminated.
    
    n_iter = 0 #Counter for iterations

    while True:
        n_iter += 1

        #Update
        next_state = next_index[curr_state] 
        mask = (next_state == prec_state) #If a direct backward step has happened
        next_state[mask] = second_next_index[curr_state][mask] #Correct it

        prec_state, curr_state = curr_state, next_state #Advance
        
        for i in range(L):
            visited[i][curr_state[i]] = 1
        
        curr_tot_visited = visited.sum()
        
        if curr_tot_visited > prec_tot_visited: #If some trial has visited a new element
            curr_patience    = max_patience
            prec_tot_visited = curr_tot_visited
        else:
            curr_patience -= 1

        if curr_patience <= 0: #Exit condition
            break

    lengths = np.sum(visited, axis=1) 

    return np.mean(lengths)
```

```{python}
simulate_sparse_dynamics(1)
```

```{python}
# %timeit simulate_sparse_dynamics(1, L=100, N=10000, f=0.01)
```

```{python}
# @njit(parallel=True)
# def test(L = 100, N = 10000, f = 0.01, n_rep=1000):
#     s = [np.float(x) for x in range(0)]
#     for i in prange(n_rep):
#         s.append(simulate_sparse_dynamics(1, L=L, N=N, f=f))
#     return s

# # %time arr = test(L = 100, N = 10000, f=0.01, n_rep=10000)
```

```{python}
#Compute statistics 
list_lengths = [8, 16, 32, 64, 128, 256, 512]
frequencies = [0.01, 0.05, 0.1]

N = 100000 #Number of neurons
n_rep = 100

stats = {}

for f in tqdm(frequencies):
    results = {}
    print(f'---f = {f}---')
    for l in tqdm(list_lengths):
        print(f'l = {l}')
        means = []
        for i in tqdm(range(n_rep)):
            r = simulate_sparse_dynamics(1, L=l, N=N, f=f)
            means.append(r)
        #r = p_umap(partial(simulate_sparse_dynamics, L=l, N=N, f=f), np.arange(n_rep))
        results[l] = means
        
    stats[f] = results
```

```{python}
import pickle
```

```{python}
with open("statistics_N10k_rep100", "wb") as file:
    pickle.dump(stats, file)
```

```{python}
#Symmetric matrix
simulate_sparse_dynamics_symm()

stats_symm = []

n_rep = 10000

for l in tqdm(list_lengths):
    print(f'l = {l}')
    means = []
    for i in tqdm(range(n_rep)):
        r = simulate_sparse_dynamics_symm(L=l)
        means.append(r)
        
    stats_symm.append(means)
```

```{python}
df_dict = {}
for f, l_stats in stats.items():
    df_dict[f] = [np.mean(arr) for arr in l_stats.values()]

df = pd.DataFrame.from_dict(df_dict, orient='index', columns=list_lengths)
```

```{python}
df.loc['symm'] = [np.mean(arr) for arr in stats_symm]
```

```{python}
df
```

```{python}
xs = np.linspace(0, 550, 1000)

with mpl2latex(True):
    fig, ax = plt.subplots(figsize=latex_figsize(wf=.8))

    ax.plot(xs, np.sqrt(1.5 * np.pi * xs), '-', c='black', label=r"$\sqrt{1.5\pi L}$")
    ax.plot(list_lengths, df.loc[0.01], '-o', c='orange', markersize=4, label='$f=0.01$')
    ax.plot(list_lengths, df.loc[0.05], '-o', c='magenta', markersize=4, label='$f=0.05$')
    ax.plot(list_lengths, df.loc[0.1], '-o', c='green', markersize=4, label='$f=0.1$')
    ax.plot(list_lengths, df.loc["symm"], '-o', c='blue', markersize=4, label='Symmetric')

    ax.set_xlabel("List length $L$")
    ax.set_ylabel("Recalled items $R$")

    plt.legend()
    ax.patch.set_facecolor('white')
    
    plt.savefig("Plots/reco_sim.pdf", transparent=True, bbox_inches='tight')
    
    plt.show()
```

```{python}
#Optimize with numba [OK]
#Do with symmetric matrix too [OK]
#Finish the plot [OK]

#Simulate dynamics with Hopfield network [TO DO]

#Verify numerically the transition probabilities (p0, p1, p2)
```
